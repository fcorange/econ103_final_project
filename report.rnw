%% LyX 2.0.6 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass{article}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{url}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
\hypersetup{
 pdfstartview={XYZ null null 1}}
\usepackage{breakurl}
\begin{document}

<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
# set global chunk options
opts_chunk$set(fig.path='figure/minimal-', fig.align='center', fig.show='hold')
options(replace.assign=TRUE,width=90)
@

\title{Stat 243 Final Project}

\author{Xi (Edward) Cai, Zhiwei (Cindy) Cai, Zixiao Chen, }

\maketitle
\section{Initialization}
Assuming initial user inputs are checked, which will be covered in section 3, initialization is performed on $k=5$, given kernel/density $g$, and lower and upper bounds of $x$. For the purpose of testing this modular, we assume the following (in particular, assume domain $D$ is the entire real line):

<<chunck1, eval=TRUE>>=
k<-5
xlb <- -Inf # lowerbound
xub <- Inf # upperbound
n<-100

######  define g ######  
g <- function(x)   (((2*pi)^-0.5)*exp(-(x)^2/2)) 
# given test function as standard normal
@

Obviously, the standard normal is a log-concave function in the domain of $[-Inf, Inf]$. Next, we want to explicitly compute the derivative of $g=density$($N(0,1)$), i.e. the function $h$.

<<chunck2, eval=TRUE>>=
######  log g = h ######  
composite<-function(f,g) function(...) f(g(...))
f <- function(x) log(x);
h <- composite(f, g)
h(1)
@

Let us make sure the function composition works. Manually check: $h(1) = log\frac{1}{\sqrt{2\pi}}-\frac{1}{2}=-1.418939$. Then, we want to check boundries. Privously, we've ensured that the mode occurs in the boundries that user inputs. Now we'd to truncate were the boundries specified unbounded.

<<chunck3, eval=TRUE>>=
######  checking Inf ######  
mode <- try(optim(0,h, upper=xub, lower =xlb, control=list(fnscale=-1),method= "L-BFGS-B")[1],silent=T)
if (class(mode)=="try-error"){
   warning("Mode not found in range. Please check your kernel/density or change xlb/xub.")
   return()
}
if (xub == Inf){
  xub <- mode$par + 10 # arbitary number bounds mode if D specified unbounded
}
if (xlb == -Inf){
   xlb <- mode$par - 10
}
@

In the above setting, we have (in default unbounded configurations) the first sample point has positive derivative and the last sample point has negative derivative, i.e. $h'(T_k[1])>0$ and $h'(T_k[k])<0$. Also, it's worth noting that the boundries were truncated from $[-Inf, Inf]$ to $[mode-10, mode+10]$. 

<<chunck4, eval=TRUE>>=
sample <- vector()   # Vector that stores all the sampled points (different from T_k)
######  evenly initialize  find T_k in D ######  
compute_T_k <- function(k,xlb,xub){ # draw k integers from domain D
 T_k <- rep(0,k) # initialize global T_k
 T_k[1] <- xlb
 T_k[k] <- xub
 for (i in 2:(k-1)){
   T_k[i] <- T_k[i-1] + (xub-xlb)/(k-1)
 }
 return(T_k)
}
T_k <- compute_T_k(k,xlb,xub)   # Initialize the evenly spaced x points on domain D
T_k

###### function evaluated at T_k  ######  
compute_h_k <- function(T_k, h){
 return(h(T_k))
}
h_k <- compute_h_k(T_k, h) # Obtain the values of h evaluated at T_k 
h_k
@


We set the initial values evenly from $T_k$, and evalute each point with respect to function $h$ to obtain $h_k$. We'd like to compute derivatives of the function $h$ at each initial point, i.e. $h'(T_k)$. We use $numDeriv$ package to perform this job, and further realize that it can be done in a vectorized fashion, which simply is:

<<chunck5, eval=TRUE>>=
library(numDeriv)
h_k_prime <- grad(h, T_k)   # Obtain the derivative of h evaluated at T_k
h_k_prime
@
In light of the standard normal, $h'(x) = (log\frac{1}{\sqrt{2\pi}}-\frac{x^2}{2})'= -x$. Thus, our $h_{k.prime}$ is simply the inverse of our $T_k$. Subsequentially, we compute the tangency intersections $z_k$.

<<chunck6, eval=TRUE>>=
###### z_k coordinates ######  
compute_z_k <- function(T_k, h_k, h_k_prime){  # tangent line intersections
 z_k <- rep (0, k-1)
 for (i in 1:k-1){
   z_k[i] <- (h_k[i+1]-h_k[i]-T_k[i+1]*h_k_prime[i+1]+T_k[i]*h_k_prime[i])/(h_k_prime[i]-h_k_prime[i+1])
 }
 return(z_k)
}
z_k <- compute_z_k(T_k, h_k, h_k_prime) # Obtain the intersections of tangent lines (k-1 elements)
z_k[k] <-T_k[k]
@

To make everything easy to manipulate, we will put the our data into a dataframe. Notice that $z_k$, the tangency intersections, has one less value thus we'd manually add a dummy value to ensure equal length. Also, $A_k$ is the area of each exponentiated trapezoid. For the time being, we initilize the vector to compile the dataframe.

<<chunck7, eval=TRUE>>=
A_k <- rep(0,length=k) # Initialize the vector of area
# Create a data frame
data <- data.frame(T_k,h_k,h_k_prime,z_k,A_k)
names(data) <- c("T_k","h_k","h_k_prime","z_k","A_k")
data
@

Before we proceed to compute upperbound and lowerbound, we'd want to consider a special case when the underlying distribution provided was $uniform$. In such case, we have developed a test for the $z_k$ vector. If any vector element was NA (i.e. as a result of tangent lines being parallel to the x-axis), we prompt the following warning:

<<chunck8,eval=TRUE>>=
if(any(is.na(z_k))){
 warning("Your kernel is uniform, please sample with runif() instead.")
 return()
}
@

The reason for the above is that we've encountered an error while testing ARS. We finally debugged down to the area vector, one of whose element reported NA. Thus, we realized that the drivative at that specific point was $0$. In the sampling modular (about statistic $S_k$), we will have to divide a zero quantity (i.e. the derivative at that point) - which, led to the error. Hence, similar to an uniform distribution, we consider $h'(x)$ a special case (and, please refer to the sampling modular for more). Next, we want to construct the upperbound function and test it. 

<<chunck9,eval=TRUE>>=
###### upper bound ######  
# returns a function u_x(x)
# If we want u_x(x) evaluated at x*, call u_x(h_k,h_k_prime,z_k,T_k)(x)
# Note: not u_x(x*)(x*)
compute_u_k <- function(data,x) {
 with(data,{
    if ((T_k[1] <= x) && (x < z_k[1])){
      return (function(x) (h_k[1] + (x-T_k[1])*h_k_prime[1]))
    }
    for (i in 1:(length(T_k)-2)){
      if(z_k[i] <= x && x < z_k[i+1]){
        return (function(x) (h_k[i+1] + (x-T_k[i+1])*h_k_prime[i+1]))
      }
    }
   if ((z_k[length(T_k)-1] <= x) && (x <= T_k[length(T_k)])){
     return (function(x) (h_k[length(T_k)] + (x-T_k[length(T_k)])*h_k_prime[length(T_k)]))
    }
  })
}
@

Let us choose $x=5.8$ in the truncated domain $[-10,10]$. To find out the line segment bounding the neighborhood $x=5.8$, take a look at $z_k$ and realize the line segment is the line tangent to point (5, h(5)). (Note, $x=5.8$ in the range [5, 10]).

<<chunck10,eval=TRUE>>=
z_k
T_k
@

Hence, we'd like to compute the gradient at 5 and solve for the linear equation. Below indicates the line has slope $k=-5$, and y-intercept $b=11.58106$.

<<chunck11, eval=TRUE>>=
grad(h, 5)
h(5)-grad(h, 5)*5
@

Further, we can show the $u_x$ we defined is an upperbound of $h(x)$.

<<chunck12, eval=TRUE>>=
compute_u_k(data,5.8)(5.8)
-5*5.8+11.58106
@

Similarly, we can check validity of our lowerbound function.

<<chunck13, eval=TRUE>>=
###### lower bound ######  
compute_l_k <- function(T_k,h_k,x) {
  for (i in 1:(length(T_k)-1)){
   if(T_k[i] <= x && x < T_k[i+1]){
     return(function(x) ((T_k[i+1]-x)*h_k[i]+(x-T_k[i])*h_k[i+1])/(T_k[i+1]-T_k[i]))
    }
  }
  if (x == T_k[length(T_k)]){
    return(function(x) ((T_k[length(T_k)]-x)*h_k[length(T_k)-1]+(x-T_k[length(T_k)-1])*h_k[length(T_k)])/(T_k[length(T_k)]-T_k[length(T_k)-1]))
 }
}
@

Again, take $x=5.8$, the lowerbound line has slope $k=-7.5$ and $b=24.08106$, thus $y=-7.5 \times x + 24.08106$.

<<chunck14, eval=TRUE>>=
T_k
compute_l_k(T_k,h_k,5.8)(5.8) # 1st 5.8 used in if statements, 2nd 5.8 used as an evaluation point
-7.5 * 5.8 + 24.08106
@

Finally, let us plot the $h(x)$, $u_x$, and $l_x$ on the same graph.

<<chunck15>>=
xval <- seq(xlb, xub, by = 0.01)
plot(xval, h(xval), pch=".", col="red", main="h(x), u_x, and l_x")
upper <- 0
for (i in 1:length(xval)){
  upper[i] <- compute_u_k(data, xval[i])(xval[i])
}
points(xval,upper,pch=".", col="blue")
lower <- 0
for (i in 1:length(xval)){
  lower[i] <- compute_l_k(T_k,h_k,xval[i])(xval[i])
}
points(xval,lower,pch=".", col="yellow")
@

Finally, we'd like to test the area function that computes each exponentiated trapezoid underneath the piece-wise upperbound $u_x$. Let us initialize our area function, entitled "$A()$".

<<chunck16>>=
### Function A computes area between i-1 and i in z_k
A <- function(i, data){ 
  with(data,{
    a<-h_k_prime[i]
    b<-h_k[i]-T_k[i]*a
    if(a==0){
      return(exp(b)*(z_k[i]-z_k[i-1]))
    }else if (i==1){
      return (-(exp(a*T_k[1]+b)-exp(a*z_k[1]+b))/a)
    }else{
      return (-(exp(a*z_k[i-1]+b)-exp(a*z_k[i]+b))/a)
    }
  })
} 
@
Let us say we are interested in the $2^{nd}$ trapezoid (note: $k=5$, thus $T_k$ has 5 elements and $z_k$ has 4 meaningful elements). In light of the above log standard normal example, the $2^{nd}$ trapezoid has an area equal to intergrating on the log standard normal curve from $z_k[1]$ to $z_k[2]$.

<<chunck17>>=
composite<-function(c,d) function(...) c(d(...))
c<-function(x) compute_u_k(data,T_k[2])
d<-function(x) exp(x)
e <-composite(f,g)
integrate(e, z_k[1], z_k[2])
## Whoops. This area should be positive as integrant is exp
@

We see that $integrate()$ cannot run on composite function in r. Hence, we have to approximate the area underneath exponentiated piece-wise upperbound $u_k$ ourselves. From below, we see that particular line segment of the $2^{nd}$ trapezoid is $y = 5 \times x + 11.58106$.

<<chunck18>>=
h_k_prime[2]
T_k[2]
h_k[2]
@

By the following math, we are able to compute each of the exponentiated trapezoid. $\int_{z_k[1]}^{z_k[2]} \mathrm{e}^{5 \times x + 11.58106}\,\mathrm{d}x = \frac{1}{5}e^{5 \times x + 11.58106} |_{z_k[1]}^{z_k[2]}$.

<<chunck19>>=
(exp(5*z_k[2]+ 11.58106)-exp(5*z_k[1]+ 11.58106))/5
A(2,data)
@

It proves that our area function works good. Note that as we approximate, we are doing multiplications which result in a loss of precision. Finally, we put the pieces together and update our data frame.

<<chunck20>>=
for (i in 1:length(T_k)) {                    
 A_k[i] <- A(i, data)
}
data$A_k <- A_k # update A_k in data frame
@

\section{Sampling and Updating}
The sampling and updating steps are performed in a while loop. While desired the sample size \texttt{n} is not reached, the function continue to sample and update if needed. In the sampling step, we first need to find the cumulative areas under each piece-wise curve $s_{k}(x)$ from $z_{j-1}$ to $z_{j}$. The \texttt{sample\_val()} function will return a vector of $x^{*}$ and $u^{*}$ sampled. Then we need to compute $u_{k}(x^{*})$ and $l_{k}(x^{*})$ and pass these parameters into \texttt{squeeze\_test} and \texttt{rejection\_test}. If squeeze test fails and $h_{k}(x^{*})$ is evaluated, then we need to add this point $x^{*}$ into our initial set of $x$'s $T_{k}$, and update all the changes accordingly with the \texttt{update()} function.

\subsection{Sampling}
Now we have $k=5$ initial points in $T_{k}$ and $k$ tangent lines which intersect at $z_{j}, j=1,...,k-1$. These partition our area under the curve $s_k(x)$ into $k$ pieces, each including one point in $T_{k}$. For example, piece $j$ under the curve contains $x_{j}$, and its bounds are $z_{j-1}$ and $z_{j}$. We want to sample an $x^{*}$ from the curve $s_{k}(x)$, and a random number $u^{*}$ from \texttt{uniform(0,1)}.

\begin{enumerate}
  \item To sample an $x^{*}$ from $s_k(x)$, we are going to do this in two steps:
  \begin{itemize}
    \item Sample one piece from the $k$ pieces using a random number $u^{'}$: 
    
    In order to do this, we need to calculate the total area under the curve and sample a uniform number $u^{'}$ from $(0, sum(Area))$. So this uniform number now is the area we want to cover with our sample $x^{*}$, i.e., we want $\int_{xlb}^{x^{*}}s_{k}(x)dx=u^{'}$. Given the cumulative area ($cumArea[j]$) for each piece $j$, we can tell by the value of $u^{'}$ which range $x^{*}$ will be in.
    \item Solving for $x^{*}$ in the chosen area:
    
    The next step would be to find the cdf of $s_{k}(x)$, and solve $cdf(x)=u$ for $x^{*}$ within the range. Since our $s_{k}(x)$ is piece-wise, our actual computation for $x^{*}$ is actually slightly different. The area we want to cover in a specific range can be expressed as $u^{'}-cumArea[j-1]$, and we then solve for $x^{*}$ such that $\int_{z_{j-1}}^{x^{*}}s_{k}(x)dx=u^{'}-cumArea[j-1]$. By doing all the algebra, we are able to find a closed form of $x^{*}$ depending on the slope $a$ and intercept $b$ of $u_{k}(x)$, $x_{j-1}$ and $u^{'}-cumArea[j-1]$. We want to solve $x^{*}$ where $\int_{z_{j-1}}^{x^{*}}s_{k}(x)=u^{'}-cumArea[j-1]$.
    
    By doing the integral, we get
    
    $$\frac{e^{ax+b}}{a}|^{x^{*}}_{z_{j-1}}=u^{'}-cumArea[j-1]$$ where $$a=h^{'}(x_{j}), b=h(x_{j})-ax_{j}$$
    
    Expanding everyting out and reorganizing the equation, we have:
    
    $$x^{*}=\frac{log[e^{az_{j-1}+1}+(u^{'}-cumArea[j-1])a]-b}{a}$$
    
    Note that we have two special cases here. When $i=1$, our starting value for $x^{*}$ is $T_k[1]$, since $z_{0}$ is not defined in our vector of $z_{j}$. Also, when the slope of $u_k(x)$ is zero for the chosen piece, we need to handle the algebra a little different.
    
    When the slope is zero, $e^{b}|^{x^{*}}_{z_{j-1}}=u^{'}-cumArea[j-1]$.
    
    $$x^{*}=e^{b}(u^{'}-cumArea[j-1])+z_{j-1}$$
  \end{itemize}
  \item Then sample $u^{*}$ from \texttt{uniform(0,1)}, which we would make use of in the squeezing and rejection tests. Finally, the \texttt{sample\_val()} function returns our sampled $x^{*}$ and $u^{*}$ to the parent function \texttt{ars()}
<<code_sample_val, eval=FALSE>>=
sample_val <- function(data,cumArea) {
  with(data, {
    # sample x*: CDF(x*)=temp-cumArea
    temp<-runif(1)*sum(A_k)
    k<-length(T_k)
    for (i in 1:k){
      a<-h_k_prime[i]
      b<-h_k[i]-T_k[i]*a
      if(i==1 && temp<cumArea[1]){
        x_star<-(log(exp(a*T_k[1]+b)+temp*a)-b)/a
        break
      }else if(temp>=cumArea[i-1] && temp<cumArea[i]){
        if (a==0){
          x_star<-(temp-cumArea[i-1])/exp(b)+z_k[i-1]
          break
        }
        x_star<-(log(exp(a*z_k[i-1]+b)+(temp-cumArea[i-1])*a)-b)/a
        break
      }
    }
    # sample u* from uniform(0,1)
    u_star<-runif(1)
    return(c(x_star, u_star))
  })
}
@
\end{enumerate}

\subsection{Squeezing Test and Rejection Test}
With $x^{*}$, $u^{*}$ and the values of $u_k(x)$ and $l_k(x)$ evaluated at $x^{*}$, we can now perform the squeezing test. If the squeezing test returns TRUE, then $x^{*}$ will be accepted and stored in our sample vector. Otherwise, $h_k(x^{*})$ will be evaluated and the rejection test will be performed. If the rejection test is passed, $x^{*}$ will be added into the sample vector.
<<code_squeeze_rejection, eval=FALSE>>=
squeeze_test <- function(x_star, u_star,l_xstar,u_xstar) {
  test<-exp(l_xstar-u_xstar)
  Boolean<-ifelse(u_star<=test,T,F)
  # T=accept, F=reject
  return(Boolean)
}

rejection_test <-function(x_star, u_star,u_xstar,h_xstar) {
  test<-exp(h_xstar-u_xstar)
  Boolean<-ifelse(u_star<=test,T,F)
  return(Boolean)
}
@

\subsection{Updating}
The code for the updating part is listed below (function \texttt{update()}):
<<code_update, eval=FALSE>>=
update <- function(x_star, data, u_k, l_k,h) { 
  with(data,{
    T_k <- sort(append(data$T_k, x_star))
    position <- (which(T_k == x_star) - 1)
    h_k <- append(data$h_k, compute_h_k(x_star, h), after = position)
    h_k_prime <- append(data$h_k_prime, grad(h, x_star), after = position)
    z_k <- compute_z_k(T_k, h_k, h_k_prime)
    z_k <- c(z_k,tail(T_k,n=1))
    A_k <- rep(0,length=length(T_k))
    data <- data.frame(T_k,h_k,h_k_prime,z_k,A_k)
    for (i in 1:length(T_k)) {                    
      A_k[i] <- A(i, data)
    }
    data$A_k <- A_k
    
    return(data)
  })
}
@

When $h(x^{*})$ and $h^{'}(x^{*})$ were evaluated, we need to update the data frame we had, namely, to add the $x^{*}$ into the $T_{k}$ vector so that the number of elements in $T_{k}$ goes from $k$ to $k+1$. To do so, $x^{*}$ is appended into the $T_{k}$ vector and then the vector is sorted. The position of the new $x^{*}$ is then recorded so that vectors $h\_k$, $h\_k\_prime$, $z\_k$ and $A\_k$ were all updated. Finally, $cumArea$ was updated as well based on the new $A\_k$ vector.

\section{Checking Validity}
\subsection{Checking Log-concavity}
When the user inputs the desired function, it is hard to check whether the input function is log-concave or not. Instead of writing an algorithm to check the log-concavity at this stage, we performed a bounding-check at each update. More specifically, when the data frame is updated, we will check on the mid-points of $T_{k}$, in terms of whether or not the upper and lower bounds are really bounding the values of the log-density, or in other words, we wish to have (for all the mid-points of $T_{k}$):

$$u(x)\geq h(x), l(x)\leq h(x)$$

If the data did not pass the test, a warning will be displayed and the \texttt{ars()} will stop processing. All of the above was done in function \texttt{check\_concave()}:

<<code_check_concavity, eval=FALSE>>=
check_concave <- function(data,h) {
  sample_points <- vector()
  for (i in 1:(length(data$T_k)-1)) {
    sample_points[i] <- mean(c(data$T_k[i],data$T_k[i+1]))
  }
  u_k <- vector()
  for (i in 1:length(sample_points)){
    u_k[i]<-compute_u_k(data,sample_points[i])(sample_points[i])
  } 
  l_k <- vector()
  for (i in 1:length(sample_points)){
    l_k[i]<-compute_l_k(data$T_k,data$h_k,sample_points[i])(sample_points[i])
  }
  return(sum((sum(u_k < h(sample_points))==0) + (sum(l_k > h(sample_points))==0)) == 2)
}
@

\subsection{Checking User Input}
When user inputs the arguments to the \texttt{ars()} function, we have to make sure that the inputs are reasonable values. Namely, we will check the following items:
\begin{itemize}
  \item The sample size $n$ is an integer and is sufficiently large ($>5$ in our case)
  \item The density function $g$ is a function
  \item The upper bound $xub$ is larger than or equal to the lower bound $xlb$
\end{itemize}
This part was done using the following code:
<<code_check_input, eval=FALSE>>=
check_input <- function(g,n,xlb,xub) {
  if ((n<5)||(n%%1!=0)) {
    warning("Sample size must be a bigger integer")
    return()
  }
  if(xlb>=xub) {
    warning ("Lower bound must be smaller than the upper bound")
    return()
  }
  if (typeof(g)!="closure") {
    warning("Input density is not a function")
    return()
  }
}
@


\section{Testing}
We tested our function \texttt{ars()} with different inputs, especially with different log-concave and non log-concave functions. Also we tested the \texttt{ars()} function where the inputs are not valid.

\subsection{Testing on Log-concave Functions}
\subsubsection{Standard normal}
The input parameters we used here are:
\begin{itemize}
  \item $n=20000$
  \item $xlb=-Inf$
  \item $xub=Inf$
\end{itemize}
The density is given by:
$$f(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}}$$
Some summary statistics of the sampled values are listed below:
<<stat_standard_normal, eval=FALSE>>=
>   samp01<-ars(g,n=20000,xlb=-Inf,xub=Inf)
>   summary(samp01)
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-4.976000 -0.675600 -0.004458  0.000150  0.681500  3.905000
@

<<plot_standard_normal, echo=FALSE, fig.width=5, fig.height=5>>=
hist(samp01, main="Sampling from standard normal", xlab="Sampled values", freq=FALSE)
xaxis <- seq(-5,5,0.001)
lines(xaxis, g1(xaxis), pch=".", col="red")
legend(-4.5,0.38, col=c("red"),lty=1,legend=c("True Function Value"),cex=0.6)
@

\subsubsection{Standard normal kernel with mean = 3}
The input parameters we used here are:
\begin{itemize}
  \item $n=20000$
  \item $xlb=-1$
  \item $xub=Inf$
\end{itemize}
The density is given by:
$$f(x)=e^{-\frac{(x-3)^{2}}{2}}$$
Note that in this case since the density function is not normalized, the actual plot of the function will be deviated from the frequency histogram of the samples.
Some summary statistics of the sampled values are listed below:
<<stat_normal_kernel, eval=FALSE>>=
>   samp001<-ars(g,n=20000,xlb=-1,xub=Inf)
>   summary(samp001)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-0.9564  2.3110  2.9960  2.9980  3.6830  6.5580 
@

<<plot_normal_kernel, echo=FALSE, fig.width=5, fig.height=5>>=
hist(samp001, main="Sampling from normal kernel with mean = 3", xlab="Sampled values", freq=FALSE, ylim=c(0,1))
xaxis <- seq(-1,6,0.001)
lines(xaxis, g2(xaxis), pch=".", col="red")
legend(-0.7,0.9, col=c("red"),lty=1,legend=c("True Function Value"),cex=0.6)
@

\subsubsection{Gamma(2,2)}
The input parameters we used here are:
\begin{itemize}
  \item $n=20000$
  \item $xlb=0.01$
  \item $xub=Inf$
\end{itemize}
The density is given by:
$$f(x)=0.25xe^{-\frac{x}{2}}$$
Some summary statistics of the sampled values are listed below:
<<stat_gamma, eval=FALSE>>=
>   samp02<-ars(g,n=20000,xlb=.01,xub=Inf)
>   summary(samp02)
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
 0.02073  1.90700  3.29100  3.81400  5.23600 12.00000
@

<<plot_gamma, echo=FALSE, fig.width=5, fig.height=5>>=
hist(samp02, main="Sampling from Gamma(2,2)", xlab="Sampled values", freq=FALSE)
xaxis <- seq(0,12,0.001)
lines(xaxis, g3(xaxis), pch=".", col="red")
legend(8,0.16, col=c("red"),lty=1,legend=c("True Function Value"),cex=0.6)
@

\subsubsection{Unnormalized Gamma(3,2) Kernel}
The input parameters we used here are:
\begin{itemize}
  \item $n=20000$
  \item $xlb=0.01$
  \item $xub=Inf$
\end{itemize}
The density is given by:
$$f(x)=x^{2}e^{-\frac{x}{2}}$$
Again, since the density function is not normalized, the actual plot of the function will be deviated from the frequency histogram of the samples.
Some summary statistics of the sampled values are listed below:
<<stat_gamma_kernel, eval=FALSE>>=
>   samp003<-ars(g,n=20000,xlb=.01,xub=Inf)
>   summary(samp003)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.1387  3.3790  5.2050  5.6440  7.4800 14.0000 
@

<<plot_gamma_kernel, echo=FALSE, fig.width=5, fig.height=5>>=
hist(samp003, main="Sampling from a unnormalized Gamma(3,2) kernel", xlab="Sampled values", freq=FALSE, ylim = c(0,2.2))
xaxis <- seq(0,14,0.001)
lines(xaxis, g4(xaxis), pch=".", col="red")
legend(8,2, col=c("red"),lty=1,legend=c("True Function Value"),cex=0.6)
@

\subsubsection{Beta(2,2) Kernel}
The input parameters we used here are:
\begin{itemize}
  \item $n=20000$
  \item $xlb=0.01$
  \item $xub=0.99$
\end{itemize}
The density is given by:
$$f(x)=\frac{x(1-x)}{beta(2,2)}$$
Some summary statistics of the sampled values are listed below:
<<stat_beta_kernel, eval=FALSE>>=
>   samp04<-ars(g,n=20000,xlb=.01,xub=.99)
>   summary(samp04)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.0102  0.3285  0.4978  0.4984  0.6708  0.9899 
@

<<plot_beta_kernel, echo=FALSE, fig.width=5, fig.height=5>>=
hist(samp04, main="Sampling from a Beta(2,2) kernel", xlab="Sampled values", freq=FALSE, ylim = c(0,2.2))
xaxis <- seq(0,1,0.001)
lines(xaxis, g5(xaxis), pch=".", col="red")
legend(0,1.8, col=c("red"),lty=1,legend=c("True Function Value"),cex=0.6)
@

\subsection{Testing on Non Log-concave Functions}
\subsubsection{Normal mixture}
The input parameters we used here are:
\begin{itemize}
  \item $n=20000$
  \item $xlb=0.01$
  \item $xub=Inf$
\end{itemize}
The density is given by:
$$f(x)=\frac{2}{\sqrt{2\pi}}e^{-\frac{(x-4)^{2}}{2}} + \frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}}$$
The true density function looks like follows:
<<plot_normal_mixture, echo=FALSE, fig.width=5, fig.height=5>>=
xaxis <- seq(-5,5,0.001)
plot(xaxis, g6(xaxis), pch=".", col="red", main="Sampling from a normal mixture", xlab="Values", ylab="Density")
legend(-4.5,0.75, col=c("red"),lty=1,legend=c("True Function Value"),cex=0.6)
@
Since this is not a log-concave function, we would expect an error when executing the \texttt{ars()} function:
<<output_normal_mixture, eval=FALSE>>=
>   sample05<-ars(g,n=20000,xlb=.01,xub=Inf)
Warning message:
In ars(g, n = 20000, xlb = 0.01, xub = Inf) : Input function not concave!
@

\subsection{Testing on Bad Lower Bound/Upper Bound Input}
\subsubsection{Undefined domain of a kernel/density: beta with xlb and xub out of range}
Sometimes the inputted lower/upper bound does not give a domain where the actual density is defined. For example, the following input failed to fall within the domain of a Beta(2,2) distribution defined on $[0,1]$, thus resulted in a warning message:
The input parameters we used here are:
\begin{itemize}
  \item $n=20000$
  \item $xlb=-1$
  \item $xub=1$
\end{itemize}
The density is given by:
$$f(x)=\frac{x(1-x)}{beta(2,2)}$$
The density was plotted below with the inputted domain range highlighted:
<<bad_lower_upper_bound, echo=FALSE,fig.width=5, fig.height=5>>=
xval <- seq(0,1,0.001)
plot(xval, g7(xval), pch=".", col="red", main="Density of Beta(2,2)", xlim = c(-1.5,1.5), xlab="Values", ylab="Density")
abline(v=c(-1,1), lty=3)
legend(-0.9,1.4, col=c("red", "black"),lty=c(1,3),legend=c("True Function Value","Input Domain"),cex=0.6)
@
It's not surprising that we will have a warning message if we execute the \texttt{ars()} function with these inputs:
<<output_bad_lower_upper_bound, eval=FALSE>>=
>   samp04d<-ars(g,n=20000,xlb=-1,xub=1)
Warning message:
In ars(g, n = 20000, xlb = -1, xub = 1) :
  Mode not found in range. Please check your kernel/density or change xlb/xub.
@

\subsection{Testing on a Uniform Density}
In the case where we are sampling from a uniform density, a warning message will be displayed to inform the user to use \texttt{runif()} function instead.
The input parameters we used here are:
\begin{itemize}
  \item $n=20000$
  \item $xlb=-1$
  \item $xub=1$
\end{itemize}
The density is given by:
$$f(x)=1$$
<<output_uniform, eval=FALSE>>=
>   sampu<-ars(g,n=20000,xlb=-1,xub=1)
Warning message:
In ars(g, n = 20000, xlb = -1, xub = 1) :
  Your kernel is uniform, please sample with runif() instead.
@

\subsection{Testing on a General Bad Input}
In this case, the user tried to sample from a Beta(2,2) distribution defined on $[0,1]$ with an input range being $[-1,1]$. Also, he specified the number of samples $n$ to be 2.5, which is not an integer. In this case, our \texttt{ars()} function will return two warning messages:
<<output_general_bad, eval=FALSE>>=
>   samp04d<-ars(g,n=2.5,xlb=-1,xub=1)
Warning messages:
1: In check_input(g, n, xlb, xub) : Sample size must be a bigger integer
2: In ars(g, n = 2.5, xlb = -1, xub = 1) :
  Mode not found in range. Please check your kernel/density or change xlb/xub.
@

\section{Individual Team Member Contributions}
\begin{tabular}{lrrr}
\hline
Name & Contributions &\\
\hline
Xi (Edward) Cai & Initializing functions for T\_k, h\_k, h\_k\_prime, z\_k, Area A\_k, u\_k, l\_k &\\
Zhiwei (Cindy) Cai &Sampling and Squeezing/Rejection testing functions; test() function &\\
Zixiao Chen &Updating function, inputs and log-concavity checking functions &\\
\hline
\\
\end{tabular}
\\



\end{document}
